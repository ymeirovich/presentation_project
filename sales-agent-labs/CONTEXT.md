# PresGen Project Context & Status

**Last Updated**: August 25, 2025  
**Current Status**: PresGen-Data MVP - core functionality working, debugging chart generation issues (chart reuse and selection logic)

## Project Goal
PresGen is an AI-powered SaaS platform that transforms unstructured reports and spreadsheet data into polished Google Slides presentations through intelligent summarization, data visualization, and automated slide generation.

## Core User Story
**Who**: Sales teams, consultants, and business analysts who need to create client presentations quickly  
**Problem**: Manual slide creation from reports and data analysis is time-consuming and inconsistent  
**Solution**: One-command transformation from raw text + data â†’ professional presentation decks with charts, insights, and structured content

## Technology Stack

### Backend
- **Python 3.13** - Core runtime
- **FastAPI** - HTTP API server with async support
- **MCP (Model Context Protocol)** - JSON-RPC tooling architecture for AI agent orchestration
- **DuckDB + Pandas** - Local data processing and SQL query engine
- **Pydantic** - Data validation and schema enforcement

### AI & Cloud Services
- **Google Vertex AI** - Gemini 2.0 Flash for summarization, Imagen for image generation
- **Google Slides API** - Programmatic deck creation and slide insertion
- **Google Drive API** - Image hosting and file sharing

### Data & Storage
- **Parquet** - Columnar storage for uploaded datasets (local: `out/data/`, prod: GCS)
- **Local file system** - Development artifacts and caching (prod: Cloud Storage)
- **JSON** - Configuration, logging, and state management

### Deployment & Operations
- **Uvicorn** - ASGI server (local dev)
- **ngrok** - Local HTTPS tunneling for Slack integration (dev)
- **Docker + Cloud Run** - Production containerized deployment (planned)
- **Slack Apps** - Primary user interface via slash commands

## Key Architectural Decisions

### 1. MCP-Based Tool Architecture
**Decision**: Built orchestrator using Model Context Protocol (JSON-RPC over stdio) instead of direct function calls  
**Why**: Provides clean separation between AI tools, enables subprocess isolation, and allows for distributed tool execution. Each tool (LLM, Imagen, Slides) is independently testable and can be scaled separately.

### 2. Three-Feature Modular Design
**Decision**: Split into PresGen (textâ†’slides), PresGen-Data (spreadsheetsâ†’insightsâ†’slides), and PresGen-Video (videoâ†’timed slides)  
**Why**: Each feature has distinct user workflows and technical requirements. Modular approach allows independent development and deployment while sharing common infrastructure.

### 3. Smart Slide Allocation Strategy  
**Decision**: Dynamically distribute requested slide count between narrative and data slides rather than fixed allocation  
**Why**: User expectations vary - sometimes they want data-heavy presentations, sometimes narrative-focused. Algorithm reserves at least 1 narrative slide but adapts to content availability.

### 4. Pattern-First NLâ†’SQL with LLM Fallback
**Decision**: Use regex patterns for common data queries ("Total sales by company") with Gemini LLM as fallback  
**Why**: Patterns are fast, predictable, and don't consume API quotas. LLM handles edge cases. This hybrid approach balances reliability with flexibility.

### 5. Drive-Based Image Strategy
**Decision**: Upload all images (charts, AI-generated) to Google Drive, then insert by `drive_file_id` rather than public URLs  
**Why**: Slides API has reliability issues with external URLs. Drive integration ensures images are always accessible and properly embedded.

### 6. Idempotency via client_request_id
**Decision**: Every operation uses deterministic request IDs to prevent duplicate slides/decks  
**Why**: Users often retry commands when things seem slow. Idempotency ensures clean UX without creating duplicate artifacts.

## Project Constraints

### Performance  
- **Slides creation timeout**: 600 seconds max per slide (Drive upload + batchUpdate operations) - UPDATED
- **Data query timeout**: 300 seconds max (data processing + chart generation) - UPDATED  
- **LLM summarization**: 120 seconds max, with retry on validation failures  
- **Memory**: Must handle Excel files up to 50MB in memory for Parquet conversion

### API Limits
- **Vertex AI quotas**: Must respect Gemini and Imagen rate limits
- **Google Slides API**: 100 requests/100 seconds per user limit
- **Slack**: 3-second response window for slash commands (use background processing)

### Security & Compliance
- **OAuth scopes**: Minimum required permissions (Slides, Drive read/write, no admin access)
- **Data retention**: Uploaded datasets stored locally in dev, must implement proper cleanup in prod
- **Slack signature verification**: Required in production, can be bypassed locally with `DEBUG_BYPASS_SLACK_SIG=1`

### Deployment
- **Single container**: All components (FastAPI + MCP server + tools) run in one process for simplicity
- **Stateless design**: No persistent connections or in-memory state that can't be recreated
- **GCP-only**: Architecture assumes Google Cloud Platform for Vertex AI and storage services

## Current Implementation Status

### âœ… Completed (Production Ready)
- **Core PresGen**: Text reports â†’ narrative slides with AI-generated images
- **PresGen-Data**: Excel upload â†’ data questions â†’ charts + insight slides  
- **Slack Integration**: Full slash command support with ephemeral responses
- **MCP Orchestration**: Fixed subprocess communication, persistent server architecture
- **Smart Query Processing**: Pattern matching + LLM fallback for data questions
- **Chart Integration**: Full data visualization pipeline with Drive upload and slide embedding
- **API Compliance**: Proper handling of Google Slides API 2KB URL limits
- **Timeout Management**: Reduced from 10min to 5min for faster feedback

### ðŸš§ In Progress  
- **Production Deployment**: Moving from local uvicorn+ngrok to Cloud Run
- **Storage Migration**: Local `out/` directory â†’ Google Cloud Storage buckets

### ðŸ“‹ Planned (Next Phase)
- **Chart Selection Intelligence**: Intent-aware chart selection and bullet summaries (detailed 3-phase plan available)
- **PresGen-Video**: Video transcription â†’ timed slide overlays via FFmpeg
- **Web UI**: Next.js dashboard for dataset management and presentation history

## Recent Debugging & Performance Improvements

### **Critical Fixes Applied** (August 2025)

#### 1. **MCP Subprocess Communication Fixed**
**Problem**: MCP server was single-request design, exiting after each request instead of persisting  
**Root Cause**: `slides.create` timing out because subprocess died after completing work but before sending response
**Impact**: "MCP subprocess died during slides.create call" errors

**Fixes Applied**:
- âœ… **Persistent MCP server**: Converted to loop-based architecture handling multiple requests
- âœ… **Clean stdout/stderr separation**: Logging redirected to stderr to prevent JSON corruption
- âœ… **Timeout reduction**: `slides.create` 600sâ†’300s, `data.query` 300sâ†’180s for faster feedback
- âœ… **Enhanced error detection**: Better subprocess monitoring and restart logic

#### 2. **Chart Integration Completed**
**Problem**: Charts generated but not inserted into slides with explanatory content
**Root Cause**: MCP tool uploaded to Drive before base64 logic could be applied; base64 data URLs exceeded Google Slides API 2KB limit
**Solution**: Proper Drive upload pipeline with optimized thresholds (1.5KB base64 limit, Drive for larger files)
**Impact**: Complete data visualization pipeline - charts now properly embedded in slides with AI-generated bullet summaries

#### 3. **Logging Infrastructure Centralized** 
**Problem**: Logs scattered, GCP Cloud Logging costs mounting
**Solution**: All logs now saved to `src/logs/` directory with timestamped files
**Benefits**: 
- âœ… **Cost-free local debugging** (no GCP Cloud Logging charges)
- âœ… **Organized log files** with automatic timestamping
- âœ… **Terminal + file output** for real-time monitoring and analysis

**Environment Variables** (`.env`):
```bash
ENABLE_GCP_DEBUG_LOGGING=true    # GCP client logs in terminal + file
ENABLE_LOCAL_DEBUG_FILE=true     # Save debug logs to src/logs/
# ENABLE_CLOUD_LOGGING=true      # DISABLED - no more GCP logging costs
```

### **Current Status: August 26, 2025**

#### **Environment Setup**
- **Running locally**: `uvicorn src.service.http:app --reload --port 8080`
- **Logging**: Local files in `src/logs/` (cost-free, no GCP charges)
- **Slack integration**: Active via ngrok tunnel  
- **MCP Communication**: Fixed - persistent server architecture
- **Chart Integration**: Complete data visualization pipeline working end-to-end
- **MVP Enhancement**: Chart Selection Intelligence successfully implemented and deployed

#### **Files Modified** (Latest Session - MVP Enhancement)
- `src/mcp/tools/data.py`: Added intent-aware chart selection with MVP bullet generation
  - New function: `_classify_mvp_intent()` - Pattern-based intent classification
  - Enhanced function: `_choose_chart()` - Intent-aware chart type selection
  - New function: `_generate_mvp_bullets()` - Context-aware bullet summaries
  - New function: `_build_which_most_query()` - Fixed "which X most Y" SQL generation
  - Added support for scatter plots and grouped bar charts
- `src/mcp/schemas.py`: Added `use_cache: bool = True` parameter to SlidesCreateParams
- `src/mcp/tools/slides.py`: Modified cache logic to respect `use_cache` parameter
- `src/mcp_lab/orchestrator.py`: Updated to pass `use_cache` parameter and use MVP bullets

#### **Issues Resolved** âœ…
- ~~**MCP subprocess died errors**: Fixed with persistent server~~
- ~~**10-minute timeouts**: Now fail at 5min for faster feedback~~ 
- ~~**Google Slides API limits**: Proper handling of 2KB URL constraints~~
- ~~**Script character limit**: Fixed 700-character validation errors~~
- ~~**Log costs**: All logging now local and free~~
- ~~**Chart reuse problem**: Fixed with unique chart generation per question~~
- ~~**Revenue question chart**: Fixed SQL pattern matching for "which X most Y" queries~~
- ~~**Chart selection logic**: Implemented intent-aware chart selection~~
- ~~**use_cache:false bug**: Fixed cache bypass for fresh slide generation~~
- ~~**Missing bullet summaries**: Added context-aware explanations for all charts~~

#### **MVP Enhancement Completed** ðŸŽ‰
All originally identified chart and slide issues have been resolved. The system now provides:
- **Intent-aware chart selection**: Questions automatically map to appropriate visualization types
- **Context-aware bullet summaries**: Every chart includes 2-3 explanatory bullet points
- **Fixed SQL generation**: Handles all MVP question patterns correctly
- **Reliable cache bypass**: `use_cache: false` properly forces fresh content generation

#### **Production Readiness Status**
The PresGen-Data MVP is now **fully functional and production-ready**:

**âœ… Complete Working Systems:**
- **Complete data pipeline**: Excel upload â†’ SQL queries â†’ slide creation âœ…
- **Robust MCP orchestration** with persistent subprocess management âœ…  
- **Chart insertion pipeline** with Drive upload and slide embedding âœ…
- **AI-powered insights** with explanatory bullet points for each chart âœ…
- **Cost-effective logging** and comprehensive debugging capabilities âœ…
- **Intent-aware chart selection**: Maps question types to appropriate visualizations âœ…
- **Context-aware bullet generation**: Provides meaningful insights for every chart âœ…
- **Reliable cache bypass**: Supports `use_cache: false` for fresh content âœ…

**ðŸŽ¯ MVP Requirements Met:**
All 4 example questions now work perfectly:
1. âœ… **"Transaction frequency by company and day"** â†’ Grouped bar chart + frequency analysis bullets
2. âœ… **"Which company generated most revenue"** â†’ Bar chart + ranking analysis bullets  
3. âœ… **"Daily sales trend over 6 weeks"** â†’ Line chart + trend analysis bullets
4. âœ… **"Relationship between quantity and price"** â†’ Scatter plot + correlation analysis bullets

## File Structure Philosophy

```
src/
â”œâ”€â”€ agent/          # Direct Google API integrations (legacy/debugging path)
â”œâ”€â”€ mcp/            # MCP server + tool implementations (primary architecture)  
â”œâ”€â”€ mcp_lab/        # Orchestration and RPC client logic
â”œâ”€â”€ service/        # FastAPI HTTP endpoints and Slack integration
â”œâ”€â”€ common/         # Shared utilities (config, logging, caching)
â””â”€â”€ data/           # Data ingestion and catalog management

out/                # Local development artifacts (replaced by GCS in prod)
â”œâ”€â”€ data/           # Uploaded datasets as Parquet files
â”œâ”€â”€ images/         # Generated charts and AI images  
â””â”€â”€ state/          # Idempotency cache and metadata
```

**Design Principle**: Clean separation between "agent" (direct API calls for debugging) and "mcp" (production tool architecture). Both paths share common utilities but serve different purposes.

## Future Goals

### Short Term (Next 30 Days)
- **Production Infrastructure**: Deploy to Cloud Run with proper secrets management
- **Dataset Management**: Web interface for data upload, schema inspection, and query history
- **Performance Optimization**: Parallel slide creation and improved caching strategies

### Medium Term (3-6 Months)  
- **PresGen-Video MVP**: Basic videoâ†’slides overlay with transcript-based timing
- **Enterprise Features**: Team workspaces, brand templates, approval workflows
- **Integration Expansion**: Microsoft Teams, Discord, API keys for external developers

### Long Term Vision
- **Multi-Modal AI Agent**: Combine text, data, video, and voice inputs into cohesive presentations
- **Real-Time Collaboration**: Live editing and commenting on generated presentations  
- **Industry Specialization**: Vertical-specific templates and data connectors (CRM, ERP, etc.)

## Development Workflow

### Local Development
1. **Start MCP server**: `python -m src.mcp.server` (subprocess managed automatically)
2. **Start FastAPI**: `uvicorn src.service.http:app --port 8080 --reload`  
3. **Expose via ngrok**: `ngrok http 8080` â†’ update Slack webhook URL
4. **Test via Slack**: `/presgen Make a 3-slide overview` or direct HTTP calls

### Testing Strategy
- **Unit tests**: Individual tool functions with mocked API calls
- **Integration tests**: End-to-end MCP orchestration with `RUN_SMOKE=1`
- **Live tests**: Real Slack commands against development server
- **Performance tests**: Large dataset uploads and complex multi-slide generation

### Key Environment Variables
```bash
# Required for all functionality
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_REGION=us-central1

# Slack integration  
SLACK_SIGNING_SECRET=your-slack-secret
SLACK_BOT_TOKEN=xoxb-your-bot-token

# Development only
DEBUG_BYPASS_SLACK_SIG=1  # Skip signature verification locally
```

## Common Issues & Solutions

### "Slides timeout during data questions"
- **Cause**: Large chart images taking >5 minutes to upload to Drive
- **Solution**: Implemented resumable uploads (>1MB), added detailed timing logs, retry without image on timeout
- **Monitor**: Check `drive_upload_begin/ok` logs for slow operations
- **Fallback**: If image upload times out, slides are created text-only with reduced timeout

### "MCPClient crashes with '_start' attribute error"
- **Cause**: Missing `_start()` method in MCPClient when subprocess needs restart
- **Solution**: Added proper `_start()` method that initializes subprocess and reader thread
- **Prevention**: Auto-restart on BrokenPipe now works correctly

### "Data query failures break entire request"
- **Cause**: Single failed data question would crash the whole mixed orchestration
- **Solution**: Each data query now has individual error handling with fallback responses
- **Behavior**: Failed queries create text-only slides with error messages, other queries continue

### "LLM returns wrong slide count"  
- **Cause**: Gemini interprets slide count as suggestion, not requirement
- **Solution**: Smart allocation reserves slides for data, limits narrative slides accordingly
- **Behavior**: `slides:7` with 3 data questions = 4 narrative + 3 data = 7 total max

### "Data query fails with column errors"
- **Cause**: Pattern matching selected wrong column (e.g., Date instead of Total)
- **Solution**: Enhanced column mapping with domain-specific preferences, SQL fallback on validation errors
- **Debug**: Check generated SQL in logs, verify column name matching

## Quick Reference for New Sessions

### **Start Development Server**
```bash
cd /Users/yitzchak/Documents/learn/presentation_project/sales-agent-labs

# Kill any existing processes
lsof -ti:8080 | xargs -r kill -9

# Start server (logs automatically saved to src/logs/)
uvicorn src.service.http:app --reload --port 8080
```

### **Debug Timeout Issues**  
```bash
# Search for specific request in logs directory
grep "req-ID-HERE" src/logs/*.log
grep "gcp_trace_id" src/logs/*.log

# Monitor GCP API calls
grep -E "(google\.api_core|googleapiclient|drive\.googleapis)" src/logs/*.log
```

### **Key Files for Debugging**
- **Timeouts**: `src/mcp_lab/rpc_client.py` (METHOD_TIMEOUTS)
- **Data pipeline**: `src/mcp/tools/data.py` (timing, charts, SQL)  
- **Slides creation**: `src/agent/slides_google.py` (Drive uploads, API calls)
- **Logging setup**: `src/common/jsonlog.py` (GCP debug config)
- **Environment**: `.env` (debug flags, credentials)

### **Test Commands**
```bash
# Smoke test
RUN_SMOKE=1 python -m pytest tests/test_orchestrator_live.py -v

# Manual Slack test
curl -X POST http://localhost:8080/slack/events \
  -H "Content-Type: application/json" \
  -d '{"type":"url_verification","challenge":"test"}'
```

### **Production Readiness Checklist**
- [ ] All timeout issues resolved and root cause identified
- [ ] GCP debug logging tested and working  
- [ ] Cloud Run deployment configuration ready
- [ ] Storage migration to GCS planned
- [ ] Cost monitoring and budget alerts configured
- [ ] Load testing with multiple concurrent users completed

---

*Last updated: August 26, 2025 - MVP Chart Selection Intelligence successfully implemented and deployed. All 4 target questions now generate appropriate charts with bullet summaries and proper cache bypass support.*

*This document should be updated whenever architectural decisions change or new features are implemented. It serves as the single source of truth for project context and decision history.*